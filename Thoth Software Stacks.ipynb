{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoth: Software Stacks\n",
    "\n",
    "Within the context of Thoth we store directed acyclic graphs (DAG) representing software packages and dependencies between these software packages. Observations are a vital part of Thoth, they denote certain facts about software packages and stacks. Recommendations are summaries generated from observations.\n",
    "\n",
    "For more details see the [Thoth Design Document](https://docs.google.com/document/d/1fsQlV7_TYx8pL97XHa0QgdTRIhm9HaFphuZi3mdhsto/edit#).\n",
    "\n",
    "## Creating Graphs\n",
    "\n",
    "This is a notebook to experiment with a set of dependency graphs. These graphs have been created from Python applications and they reflect graphs with different versions of package. We call these graphs of versioned packages a 'stack'.\n",
    "\n",
    "First of all we will include all the required modules and configure matplotlib to draw diagrams inlined in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.operators.binary import compose\n",
    "from networkx.readwrite import json_graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function that will read the output of `pipenv graph --json` from a file and create the equivalent graph using `networkx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def add_package(graph: nx.DiGraph, name: str, version: str) -> bool:\n",
    "    \"\"\"add_package() will add a versioned package to the graph.\n",
    "    \n",
    "    Args:\n",
    "        graph (networkx.Graph): the graph to add to\n",
    "        name (str):             Name of the package\n",
    "        version (str):          Version of the package\n",
    "        \n",
    "    Returns:\n",
    "        str: the UUID of the node just added or None if something failed.\n",
    "        \n",
    "    Raises:\n",
    "        TBD\n",
    "    \"\"\"\n",
    "    \n",
    "    _node_id = '{}-{}'.format(name.lower(), version)\n",
    "    # _node_id = str(uuid.uuid4())\n",
    "    graph.add_node(_node_id, name=name, \n",
    "                   version=version,\n",
    "                   component='package')\n",
    "    \n",
    "    # TODO check for errors and return None\n",
    "    \n",
    "    return _node_id\n",
    "\n",
    "def add_stack_from_file(name: str, version: str, filename: str):\n",
    "    \"\"\"add_stack_from_file() will read the output of `pipenv graph --json` and will create a networkx graph from it.\n",
    "    \n",
    "    Args:\n",
    "        name (str):     Name of the Stack\n",
    "        version (str):  Version of the Stack\n",
    "        filename (str): The filename storing `pipenv graph --json` output\n",
    "        \n",
    "    Returns:\n",
    "        networkx.Graph: The create graph.\n",
    "        \n",
    "    Raises:\n",
    "        TBD\n",
    "    \"\"\"\n",
    "    \n",
    "    data = None\n",
    "    G = None\n",
    "    \n",
    "    try:\n",
    "        with open(filename) as file:    \n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "        \n",
    "    if data is not None:\n",
    "        G = nx.DiGraph(name=name, version=version, component='stack')\n",
    "        \n",
    "        for package in data:\n",
    "            _node_id = add_package(G, name=package['package']['package_name'], \n",
    "                        version=package['package']['installed_version'])\n",
    "            \n",
    "            for dependency in package['dependencies']:\n",
    "                _dependency_node_id = add_package(G, name=dependency['package_name'], \n",
    "                            version=dependency['installed_version'])\n",
    "                \n",
    "                G.add_edge(_node_id, _dependency_node_id, relation='depends_on')\n",
    "                \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will read a set of files from the `fixtures/` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPENV_GRAPH_FILES = [\n",
    "    {\n",
    "        'name': 'tensorflow',\n",
    "        'version': '1.4.0',\n",
    "        'filename': 'fixtures/tensorflow-1.4.0.json'\n",
    "    }, \n",
    "    {\n",
    "        'name': 'tensorflow',\n",
    "        'version': '1.4.1',\n",
    "        'filename': 'fixtures/tensorflow-1.4.1.json'\n",
    "    },\n",
    "    {\n",
    "        'name': 'tensorflow',\n",
    "        'version': '1.3.0',\n",
    "        'filename': 'fixtures/tensorflow-1.3.0.json'\n",
    "    },\n",
    "    {\n",
    "        'name': 'keras',\n",
    "        'version': '2.1.2',\n",
    "        'filename': 'fixtures/keras-2.1.2.json'\n",
    "    },\n",
    "    {\n",
    "        'name': 'keras',\n",
    "        'version': '2.1.2+tensorflow-1.3.0',\n",
    "        'filename': 'fixtures/keras-2.1.2-tensorflow-1.3.0.json'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file will be read and added to our big huge global graph store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = []\n",
    "\n",
    "for entry in PIPENV_GRAPH_FILES:\n",
    "    _H = add_stack_from_file(entry['name'], entry['version'], entry['filename'])\n",
    "    \n",
    "    if _H is not None:\n",
    "        graph_store.append(_H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will create on graph from all the graph in our `graph_store` and draw it with labels added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for _G in graph_store:\n",
    "    G = compose(G, _G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here is the graph <a id='graph_drawing'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.axis('off')\n",
    "\n",
    "pos = nx.spring_layout(G, iterations=20)\n",
    "labels=dict((n,d['name']) for n,d in G.nodes(data=True))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, labels=labels, node_size=40, node_color='blue')\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "nx.draw_networkx_labels(G, pos, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next? Observations\n",
    "\n",
    "Having some software stacks represented as graphs, we can add observations to these graphs.\n",
    "\n",
    "To create some packages and observations, we will add more packages to the graph which have not been discovered by the provided graph fixtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PYPI_FILES = [\n",
    "    {\n",
    "        'name': 'numpy',\n",
    "        'version': '1.9.0',\n",
    "        'filename': 'fixtures/numpy-1.9.0.json'\n",
    "    },\n",
    "    {\n",
    "        'name': 'pandas',\n",
    "        'version': '0.21.0',\n",
    "        'filename': 'fixtures/pandas-0.21.0.json'\n",
    "    }\n",
    "]\n",
    "    \n",
    "for entry in PYPI_FILES:\n",
    "    _H = add_stack_from_file(entry['name'], entry['version'], entry['filename'])\n",
    "    \n",
    "    if _H is not None:\n",
    "        G = compose(G, _H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Observation will be a new Node in a Graph, the Observation is related to a Node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_observation(G, O, R, N) -> bool:\n",
    "    \"\"\"Add an Observation O related to Node N of Graph G by R.\n",
    "    \n",
    "    Args:\n",
    "        G (networkx.DiGraph):  The Graph\n",
    "        O (str):               The Node ID of the Observation itself\n",
    "        R (str):               The observation's relation to the node if has been observed on (edge label)\n",
    "        N (str):               The Node ID the observation has been made on/about\n",
    "        \n",
    "    Returns:\n",
    "        bool: If the Observation have been added successful.\n",
    "        \n",
    "    Raises:\n",
    "        NodeNotFound If N has not been found in G.\n",
    "    \"\"\"\n",
    "    \n",
    "    G.add_edge(N, O, relation=R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Observations\n",
    "\n",
    "#### Vulnerabilities\n",
    "\n",
    "Vulnerabilities are most often expressed by [CVEs](https://en.wikipedia.org/wiki/Common_Vulnerabilities_and_Exposures), and they are one of the observations with a negative impact.\n",
    "\n",
    "With [numpy <= 1.13.1 a CVE](https://www.cvedetails.com/cve/CVE-2017-12852/) exists. This is our first observation we are adding. It will lead to the fact that any recommendation will exclude all software stacks that include/contain numpy <= 1.31.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node('CVE-2017-12852', name='CVE-2017-12852', version='1.0.0', conclusion='blacklist')\n",
    "\n",
    "add_observation(G, \n",
    "                'CVE-2017-12852', \n",
    "                'affected_by', \n",
    "                'numpy-1.9.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you [reuse the cell above to draw the graph](#graph_drawing), you will see the additional node 'CVE-2017-12852'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral Observations\n",
    "\n",
    "#### Build Results\n",
    "\n",
    "As a matter of fact, each software stack could be associated with a build result, eg it have been build successfully (or not) by a CI pipeline. This kind of result will result in a neutral observation, as the effect is not emidiate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node('build-tensorflow-centos7-python3-37', name='tensorflow-centos7-python3-37', version='1.0.0', conclusion='build-successful')\n",
    "\n",
    "add_observation(G, \n",
    "                'tensorflow-1.4.1', \n",
    "                'built', \n",
    "                'build-tensorflow-centos7-python3-37')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Observations\n",
    "\n",
    "Positive Observation may influence the Recommendations later on. One example of a positive observation may be an increase in performance due to an optimization in the Build Environement.\n",
    "\n",
    "#### Performance Increase\n",
    "\n",
    "Due to optimizations in eg BuildEnvironment ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "The next section is just some kind of playground..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = nx.to_pandas_adjacency(G, dtype=int)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the next cell is just for debugging...\n",
    "\n",
    "Let's write the [JSON respresentation of the graph](https://networkx.github.io/documentation/stable/reference/readwrite/generated/networkx.readwrite.json_graph.node_link_data.html#networkx.readwrite.json_graph.node_link_data) to a file, so we can use it with d3. Maybe you can [click on this link](http://localhost:8080/pipenv-graph2networkx/stacks.html) and it will simpley work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stacks.json', 'w') as output:\n",
    "    data = json_graph.node_link_data(G)\n",
    "    \n",
    "    output.write(json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything worked out, you should see a graphic like the one below. On the upper right corner you see the CVE, following the links it should clearly exclude `pandas 0.21.0` from any recommendation!\n",
    "![Stacks](stacks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "<a id='recommendations'></a>\n",
    "\n",
    "This section will go into making recommendations. One of our assumption is, that we would like to create stacks will fully qualified/versioned dependencies. This way we will ensure, that the resulting graph is predictable. If no version is supplied, the latest stack version is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraph(G: nx.DiGraph, start_node) -> nx.DiGraph:\n",
    "    \"\"\"This will return the subgraph starting at a specific node\n",
    "    \"\"\"\n",
    "    nodes = nx.single_source_shortest_path(G, start_node).keys()\n",
    "\n",
    "    return G.subgraph(nodes).copy()\n",
    "\n",
    "def get_versioned_stack(name: str, version: str) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO if no version is supplied, use the latest\n",
    "    S = None\n",
    "    \n",
    "    try:\n",
    "        S = create_subgraph(G, '{}-{}'.format(name, version))\n",
    "    except nx.NodeNotFound as e:\n",
    "        print(e)\n",
    "        return None # TODO raise nx.NodeNotFound\n",
    "\n",
    "    blacklisted_packages = nx.get_node_attributes(G,'conclusion')\n",
    "    \n",
    "    for node_id in blacklisted_packages.keys():\n",
    "        if node_id in S.nodes():\n",
    "            print('This stack has been blacklisted due to {}'.format(S.nodes[node_id]))\n",
    "            return None # TODO raise StackIsBlacklisted(S.nodes[node_id])\n",
    "            \n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, lets get a stack, for example Tensorflow 1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_tf140 = get_versioned_stack('tensorflow', '1.4.0')\n",
    "\n",
    "if G_tf140 is not None:\n",
    "    nx.draw_spectral(G_tf140)\n",
    "    labels=nx.draw_networkx_labels(G_tf140, pos=nx.spectral_layout(G_tf140))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or Pandas 0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_pandas = get_versioned_stack('pandas', '0.21.0')\n",
    "\n",
    "if G_pandas is not None:\n",
    "    nx.draw_spectral(G_pandas)\n",
    "    labels=nx.draw_networkx_labels(G_pandas, pos=nx.spectral_layout(G_pandas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Recommendation\n",
    "<a id='using_a_recommendation'></a>\n",
    "\n",
    "So what is the purpos of this recommendation? We want to provide guidance to developers and recommend a full qualified software stack that is known to be 'good'. That software stack should build (to our knowledge using our refenrence build pipeline) and have no known CVE.\n",
    "\n",
    "We expect developeres to use our recommendation to create a containerized software stack, therefor a Recommendation is translated into a `Dockerfile(-snipped)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_stack_to_Dockerfile_snippet(graph: nx.DiGraph) -> str:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    rc = 'RUN pip install \\\\\\n'\n",
    "    for n in graph:\n",
    "        rc += '        {} \\\\\\n'.format(n.replace('-', '=='))\n",
    "    \n",
    "    return rc[:-3] # we remove the trailing \\\n",
    "\n",
    "\n",
    "G_tf140 = get_versioned_stack('tensorflow', '1.4.0')\n",
    "\n",
    "print(\"\"\"FROM fedora:27\n",
    "\n",
    "{}\n",
    "\"\"\".format(version_stack_to_Dockerfile_snippet(G_tf140)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
